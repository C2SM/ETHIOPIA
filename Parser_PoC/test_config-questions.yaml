scheduling:
  start_date: &root_start_date '2026-01-01T00:00' # Q(alex) what is the & meanning? Why do you need to doubly define things, wouldn't be start_date: '2028-01-01T00:00' enough?
  end_date: &root_end_date '2027-01-01T00:00'
  graph:
    init:
      tasks:
        Extpar:
          input:
            - obs data
          output:
            - extpar file
    icon:
      period: 'P2M' # Do we need the P at the beginning, isn't clear from quantifier name
      # period: 'P3M'
      # period: 'P4M'
      # period: 'P6M'
      tasks:
        preproc:
          input:
            - grid file
            - extpar file:
                date: *root_start_date # Q(alex) What does the date do, is this just metadata?
            - ERA5
          output:
            - icon input
          depends: # Q(alex) not really dependency as preproc is independent, more a "submit after" functionality to not submit too many jobs
            - ICON:
                lag: '-P4M'
                # lag: '-P6M'
                # lag: '-P8M'
                # lag: '-P12M'
        ICON:
          input:
            - grid file
            - icon input
            - restart:
                lag: '-P2M'
                # lag: '-P3M'
                # lag: '-P4M'
                # lag: '-P6M'
          output:
            - stream 1
            - stream 2
            - restart
        postproc 1:
          input:
            - stream 1
          output:
            - postout 1
        store & clean 1:
          input:
            - postout 1
            - stream 1
            - icon input
          output:
            - stored data 1
    yearly:
      period: 'P1Y'
      tasks:
        postproc 2:
          input:
            - stream 2:
                lag: ['P0M', 'P2M', 'P4M', 'P6M', 'P8M', 'P10M']
                # lag: ['P0M', 'P3M', 'P6M', 'P9M']
                # lag: ['P0M', 'P4M', 'P8M']
                # lag: ['P0M', 'P6M']
          output:
            - postout 2
        store & clean 2:
          input:
            - postout 2
            - stream 2:
                lag: ['P0M', 'P2M', 'P4M', 'P6M', 'P8M', 'P10M']
                # lag: ['P0M', 'P3M', 'P6M', 'P9M']
                # lag: ['P0M', 'P4M', 'P8M']
                # lag: ['P0M', 'P6M']
          output:
            - stored data 2
runtime: # Q(alex) is it possible to merge this information with graph (and keep runtime as name), to simplify coding logic (and probably readability, you see all at once)
  # Each task and piece of data (input and output of tasks) used to
  # define the graph is described in that section
  tasks:
    root:
      # All tasks inherit the root task properties
      host: santis
      account: g110
    Extpar:
      plugin: extpar # Q(alex) why define plugin here, isnt path to executable or plugin sufficient?
      exe: path/to/exe
      config: path/to/namelists/dir # Q(alex): isn't this just an input file that can be specified with an argument option (e.g. --config)
      uenv:
        squashfs: path/to/squashfs
        mount_point: runtime/mount/point
      nodes: 1
      walltime: '00:02:00'
    preproc:
      plugin: AiiDA Shell
      nodes: 4
      walltime: '00:02:00'
      config: path/to/config/dir
      uenv:
        squashfs: path/to/squashfs
        mount_point: runtime/mount/point
    ICON:
      plugin: ICON
      nodes: 40
      walltime: '24:00:00'
      config: path/to/namelists/dir
      uenv:
        squashfs: path/to/squashfs
        mount_point: runtime/mount/point
      exe: path/to/icon
    postproc 1:
      plugin: AiiDA Shell
      nodes: 2
      walltime: '00:05:00'
      src: path/to/src/dir
      exe: "python3 main_script_ocn.py"
      conda_env: path/to/yaml/env/file
      uenv:
        squashfs: path/to/squashfs
        mount_point: runtime/mount/point
    postproc 2:
      plugin: AiiDA Shell
      nodes: 4
      walltime: '00:05:00'
      src: path/to/src/dir
      exe: "python3 main_script_atm.py"
      conda_env: path/to/yaml/env/file
      uenv:
        squashfs: path/to/squashfs
        mount_point: runtime/mount/point
    store & clean 1:
      plugin: AiiDA Shell
      nodes: 1
      walltime: '00:01:00'
      scipt: path/to/script
    store & clean 2:
      plugin: AiiDA Shell
      nodes: 1
      walltime: '00:01:00'
      scipt: path/to/script

  data: # can we put this to root level (remove one tab), not under runtime
    # Properties of data nodes
    grid file: {type: file, abs_path: /path/to/grid/file.nc}
    obs data: {type: dir, abs_path: /some/where}
    ERA5: {type: dir, abs_path: /some/where/else}
    extpar file: {type: file, rel_path: output}
    icon input: {rel_path: output}
    restart: {type: ICON_restart, format: ncdf, rel_path: restart} # Q(alex) isnt type and ncdf redundant, what additional information do we get from type? Should be file
    stream 1: {type: ICON_output_stream, rel_path: output_1}
    stream 2: {type: ICON_output_stream, rel_path: output_2}
    postout 1: {'rel_path': output}
    postout 2: {'rel_path': output}
    stored data 1: {'abs_path': /store/some/where_1}
    stored data 2: {'abs_path': /store/some/where_2}
